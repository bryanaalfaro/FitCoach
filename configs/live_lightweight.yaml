model:
    llama2_7b_path: './Llama-2-7b-hf'
    kwargs:
        checkpoint_path: './ckpts_streamvlm/ckpts_streamvlm/state_dict.pth.tar'
        strict_checkpoint: False
        bf16: True  # Use bfloat16 for memory efficiency
        xattn_config:
            xattn_type: 'dotprod'
            xattn_block_size: 1
            adapter_insert_layers: "[6, 8, 10, 12, 14, 16, 18, 20, 22]"
            num_of_xattn_heads: 1
        trainable:
            llm: False
            xattn: False
            vision: False
        peft_config:
            r: 32
            lora_alpha: 16
            lora_dropout: 0.05
            target_modules:
                - 'q_proj'
                - 'v_proj'
                - 'k_proj'
                - 'lm_head'

evaluator:
    name: 'live_feedback_lightweight'
    kwargs:
        camera_id: 0
        exercise_type: 'squats'
    sampling_kwargs:
        do_sample: False
        temperature: 0.
        max_feedback_length: 48  # Reduced from 64 for better memory efficiency
        feats_frequency: 2  # Lower rate for less GPU usage (2 fps instead of 4)
        feedback_interval: 15.0  # Increased from 10 to 15 seconds for better memory management
